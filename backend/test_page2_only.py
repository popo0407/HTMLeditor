#!/usr/bin/env python3
"""
test_page2.htmlå°‚ç”¨ãƒ†ã‚¹ãƒˆ
test_page2.htmlã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™
"""

import asyncio
import sys
import os
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from backend.app.services.scraping_service import ScrapingService, ScrapingMode
from backend.app.models.scraping_schemas import ScrapingRequest, ScrapingResult, LoginCredentials
from backend.app.config.settings import get_settings

async def test_page2_only():
    """test_page2.htmlå°‚ç”¨ãƒ†ã‚¹ãƒˆ"""
    print("=" * 60)
    print("HTMLEditer test_page2.htmlå°‚ç”¨ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    try:
        # è¨­å®šã‚’å–å¾—
        settings = get_settings()
        print("âœ… è¨­å®šå–å¾—å®Œäº†")
        
        # ScrapingServiceã‚’åˆæœŸåŒ–
        scraping_service = ScrapingService()
        print("âœ… ScrapingServiceåˆæœŸåŒ–å®Œäº†")
        
        # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ
        test_url = "http://localhost:8080/test_page2.html"
        
        # ãƒ€ãƒŸãƒ¼ã®èªè¨¼æƒ…å ±ã‚’ä½œæˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
        credentials = LoginCredentials(
            username="testuser",
            password="testpass",
            login_url="http://localhost:8080/test_login.html"
        )
        
        request = ScrapingRequest(
            credentials=credentials,
            target_urls=[test_url],
            mode=ScrapingMode.TITLE_DATE_PARTICIPANT
        )
        print("âœ… ãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆå®Œäº†")
        print(f"   å¯¾è±¡URLæ•°: {len(request.target_urls)}")
        
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’å®Ÿè¡Œ
        print("\nğŸ“¡ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œä¸­...")
        print(f"   å¯¾è±¡URL: {test_url}")
        print(f"   ãƒ­ã‚°ã‚¤ãƒ³URL: {credentials.login_url}")
        
        results = await scraping_service.execute_scraping(request)
        
        # çµæœã‚’è¡¨ç¤º
        print("âœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†")
        print(f"   çµæœæ•°: {len(results.results)}")
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿½åŠ 
        print(f"\nğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
        print(f"   ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {results.session_id}")
        print(f"   å‡¦ç†æ™‚é–“: {results.total_processing_time:.2f}ç§’")
        if results.combined_data:
            print(f"   çµåˆãƒ‡ãƒ¼ã‚¿é•·: {len(results.combined_data)}æ–‡å­—")
        
        print("\n" + "=" * 60)
        print("ğŸ“Š ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœè©³ç´°")
        print("=" * 60)
        
        for i, result in enumerate(results.results, 1):
            print(f"\nğŸ” çµæœ {i}:")
            print(f"   URL: {result.url}")
            print(f"   ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {result.status}")
            print(f"   ãƒ¢ãƒ¼ãƒ‰: {result.mode}")
            
            if result.status == "success":
                print(f"   âœ… æˆåŠŸ")
                print(f"   ãƒ‡ãƒ¼ã‚¿é•·: {len(result.data) if result.data else 0}æ–‡å­—")
                
                # ãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã®100æ–‡å­—ã‚’è¡¨ç¤º
                if result.data:
                    preview = result.data[:100] + "..." if len(result.data) > 100 else result.data
                    print(f"   ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {preview}")
            else:
                print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {result.error_message}")
        
        print("\nğŸ‰ test_page2.htmlã®ãƒ†ã‚¹ãƒˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª
    print("ğŸš€ test_page2.htmlå°‚ç”¨ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™...")
    
    # éåŒæœŸãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    success = asyncio.run(test_page2_only())
    
    if success:
        print("\nâœ… ãƒ†ã‚¹ãƒˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
        sys.exit(0)
    else:
        print("\nâŒ ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)

