#!/usr/bin/env python3
"""
ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ©Ÿèƒ½ã®çµ±åˆãƒ†ã‚¹ãƒˆ

é–‹ç™ºãƒãƒ£ãƒ¼ã‚¿ãƒ¼ã«å¾“ã„ã€å®Ÿéš›ã®å‹•ä½œã‚’ç¢ºèªã™ã‚‹ãŸã‚ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import asyncio
import sys
import os
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from backend.app.services.scraping_service import ScrapingService
from backend.app.models.scraping_schemas import ScrapingRequest, LoginCredentials, ScrapingMode, UrlConfig

async def test_scraping_functionality():
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ©Ÿèƒ½ã®åŸºæœ¬å‹•ä½œãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ©Ÿèƒ½ã®çµ±åˆãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™...")
    
    try:
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–
        scraping_service = ScrapingService()
        print("âœ… ScrapingServiceåˆæœŸåŒ–å®Œäº†")
        
        # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆï¼ˆä¸¡æ–¹ã®ãƒšãƒ¼ã‚¸ã‚’åŒæ™‚ã«ãƒ†ã‚¹ãƒˆï¼‰
        test_request = ScrapingRequest(
            credentials=LoginCredentials(
                username="test_user",
                password="test_pass",
                login_url="http://localhost:8080/test_login.html"
            ),
            url_configs=[
                UrlConfig(
                    url="http://localhost:8080/test_page1.html",
                    mode=ScrapingMode.CHAT_ENTRIES
                ),
                UrlConfig(
                    url="http://localhost:8080/test_page2.html",
                    mode=ScrapingMode.TITLE_DATE_PARTICIPANT
                )
            ]
        )
        
        print("âœ… ãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆå®Œäº†")
        print(f"   å¯¾è±¡URLæ•°: {len(test_request.url_configs)}")
        
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ
        print("\nğŸ“¡ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œä¸­...")
        response = await scraping_service.execute_scraping(test_request)
        
        print("âœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†")
        print(f"   ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {response.session_id}")
        print(f"   å‡¦ç†æ™‚é–“: {response.total_processing_time:.2f}ç§’")
        print(f"   çµæœæ•°: {len(response.results)}")
        
        # çµæœã®è©³ç´°è¡¨ç¤º
        print(f"\n{'='*60}")
        print("ğŸ“Š ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœè©³ç´°")
        print(f"{'='*60}")
        
        for i, result in enumerate(response.results, 1):
            print(f"\nğŸ” çµæœ {i}:")
            print(f"   URL: {result.url}")
            print(f"   ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {result.status}")
            print(f"   ãƒ¢ãƒ¼ãƒ‰: {result.mode}")
            
            if result.status == "success":
                print(f"   ãƒ‡ãƒ¼ã‚¿é•·: {len(result.data) if result.data else 0}æ–‡å­—")
                if result.data:
                    print(f"   å–å¾—ãƒ‡ãƒ¼ã‚¿:")
                    print(f"   {'-'*50}")
                    print(result.data)
                    print(f"   {'-'*50}")
            else:
                print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {result.error_message}")
        
        # çµ±åˆãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
        if response.combined_data:
            print(f"\nğŸ”— çµ±åˆãƒ‡ãƒ¼ã‚¿:")
            print(f"   ãƒ‡ãƒ¼ã‚¿é•·: {len(response.combined_data)}æ–‡å­—")
            print(f"   å†…å®¹:")
            print(f"   {'='*50}")
            print(response.combined_data)
            print(f"   {'='*50}")
        
        # æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
        if response.structured_data:
            print(f"\nğŸ—ï¸ æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿:")
            if response.structured_data.title:
                print(f"   ã‚¿ã‚¤ãƒˆãƒ«: {response.structured_data.title}")
            if response.structured_data.date:
                print(f"   æ—¥ä»˜: {response.structured_data.date}")
            if response.structured_data.participant:
                print(f"   å‚åŠ è€…: {response.structured_data.participant}")
            if response.structured_data.transcript:
                print(f"   ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ: {len(response.structured_data.transcript)}æ–‡å­—")
        
        print("\nğŸ‰ çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        try:
            await scraping_service.shutdown()
            print("ğŸ§¹ ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    print("=" * 60)
    print("HTMLEditer ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ©Ÿèƒ½ çµ±åˆãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # éåŒæœŸãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
    success = asyncio.run(test_scraping_functionality())
    
    if success:
        print("\nâœ… ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
        sys.exit(0)
    else:
        print("\nâŒ ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        sys.exit(1)
